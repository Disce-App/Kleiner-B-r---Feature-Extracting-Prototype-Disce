# pages/grosser_baer.py
"""
Gro√üer B√§r ‚Äì Speaking Coach UI
Streamlit-Seite f√ºr Audio-Aufnahme und Feedback.
"""

import uuid
from datetime import datetime
import json

import streamlit as st
import requests

# Gro√üer B√§r Imports
from grosser_baer import (
    get_task,
    get_task_choices,
    process_speaking_task,
    generate_feedback,
    format_feedback_markdown,
    SessionLogger,
)

# Kleiner B√§r ‚Äì deterministische Textanalyse
from disce_core import analyze_text_for_llm

# Pretest-Loader
from config.pretest_loader import (
    load_pretest_config,
    init_pretest_state,
    should_show_pretest,
    render_pretest,
    render_level_recheck,
    get_pretest_data_for_airtable,
    get_pretest_data_for_coach_input,
    get_response as get_pretest_response,
)

# OpenAI Services (Whisper + GPT)
try:
    from openai_services import transcribe_audio, generate_coach_feedback, check_api_connection
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


# =============================================================================
# KONFIGURATION
# =============================================================================

MAKE_WEBHOOK_URL = "https://hook.eu2.make.com/2f65yl8ut90pnq2jhbi1l1ft2ytecceh"
PRETEST_CONFIG_PATH = "config/pretest_config.json"


# =============================================================================
# PAGE CONFIG
# =============================================================================

st.set_page_config(
    page_title="Gro√üer B√§r ‚Äì Speaking Coach",
    page_icon="üêª",
    layout="wide",
)

# =============================================================================
# SESSION STATE INITIALISIERUNG
# =============================================================================

if "phase" not in st.session_state:
    st.session_state.phase = "select"  # select ‚Üí record ‚Üí feedback

if "selected_task_id" not in st.session_state:
    st.session_state.selected_task_id = None

if "audio_bytes" not in st.session_state:
    st.session_state.audio_bytes = None

if "transcript" not in st.session_state:
    st.session_state.transcript = None

if "feedback_result" not in st.session_state:
    st.session_state.feedback_result = None

if "recording_start" not in st.session_state:
    st.session_state.recording_start = None

if "kleiner_baer_result" not in st.session_state:
    st.session_state.kleiner_baer_result = None

if "coach_input" not in st.session_state:
    st.session_state.coach_input = None

if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# Planungsfeld (Phase 1)
if "learner_goal" not in st.session_state:
    st.session_state.learner_goal = ""

if "learner_context" not in st.session_state:
    st.session_state.learner_context = ""

# Reflexionsfeld (Phase 3)
if "reflection_text" not in st.session_state:
    st.session_state.reflection_text = ""

if "reflection_saved" not in st.session_state:
    st.session_state.reflection_saved = False

# Nutzercode (Mini-Login)
if "user_code" not in st.session_state:
    st.session_state.user_code = ""

if "user_code_confirmed" not in st.session_state:
    st.session_state.user_code_confirmed = False

# Session-Speicherung
if "session_saved" not in st.session_state:
    st.session_state.session_saved = False

# Session-Z√§hler (f√ºr Level-Recheck)
if "session_count" not in st.session_state:
    st.session_state.session_count = 0

# =============================================================================
# PRETEST INITIALISIERUNG
# =============================================================================

init_pretest_state()
PRETEST_CONFIG = load_pretest_config(PRETEST_CONFIG_PATH)


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def generate_user_code() -> str:
    """Generiert einen zuf√§lligen 6-stelligen Nutzercode."""
    import random
    import string
    # Format: 3 Buchstaben + 3 Zahlen (z.B. ABC123)
    letters = ''.join(random.choices(string.ascii_uppercase, k=3))
    numbers = ''.join(random.choices(string.digits, k=3))
    return f"{letters}{numbers}"


def validate_user_code(code: str) -> tuple[bool, str]:
    """Validiert den Nutzercode. Gibt (is_valid, message) zur√ºck."""
    if not code:
        return False, "Bitte gib einen Code ein."
    if len(code) < 4:
        return False, "Der Code muss mindestens 4 Zeichen haben."
    if len(code) > 20:
        return False, "Der Code darf maximal 20 Zeichen haben."
    if not code.replace("_", "").replace("-", "").isalnum():
        return False, "Nur Buchstaben, Zahlen, - und _ erlaubt."
    return True, "OK"


def reset_session():
    """Setzt die Session zur√ºck f√ºr neue Aufnahme (beh√§lt Nutzercode + Pretest)."""
    st.session_state.phase = "select"
    st.session_state.selected_task_id = None
    st.session_state.audio_bytes = None
    st.session_state.transcript = None
    st.session_state.feedback_result = None
    st.session_state.recording_start = None
    st.session_state.kleiner_baer_result = None
    st.session_state.coach_input = None
    st.session_state.session_id = str(uuid.uuid4())
    st.session_state.learner_goal = ""
    st.session_state.learner_context = ""
    st.session_state.reflection_text = ""
    st.session_state.reflection_saved = False
    st.session_state.session_saved = False
    # Session-Z√§hler erh√∂hen
    st.session_state.session_count += 1
    # user_code und pretest_responses bleiben erhalten!


def logout_user():
    """Loggt den Nutzer aus (l√∂scht auch Nutzercode und Pretest)."""
    st.session_state.user_code = ""
    st.session_state.user_code_confirmed = False
    # Pretest zur√ºcksetzen
    st.session_state.pretest_responses = {}
    st.session_state.pretest_completed = False
    st.session_state.pretest_completed_at = None
    st.session_state.pretest_current_module = 0
    st.session_state.session_count = 0
    reset_session()


def build_coach_input(
    transcript_text: str,
    task: dict,
    duration: float,
    mode: str,
    kleiner_baer_result: dict,
    learner_goal: str = "",
    learner_context: str = "",
    reflection: str = "",
) -> dict:
    """Baut den JSON-Block, der sp√§ter an die LLM-Coach-API geht."""
    now = datetime.now()
    recording_start = st.session_state.get("recording_start")

    # Pretest-Daten f√ºr Coach-Input holen
    pretest_data = get_pretest_data_for_coach_input()

    return {
        # Nutzer-Identifikation
        "user": {
            "code": st.session_state.get("user_code", ""),
            "is_anonymous": not st.session_state.get("user_code_confirmed", False),
        },
        # NEU: Pretest-Daten (CEFR-Selbsteinsch√§tzung, MASQ-Scores, etc.)
        "pretest": pretest_data,
        "task_metadata": {
            "task_id": st.session_state.selected_task_id,
            "situation": task.get("situation"),
            "task": task.get("task"),
            "target_level": task.get("level"),
            "target_register": task.get("register"),
            "time_limit_seconds": task.get("time_seconds"),
        },
        "session_metadata": {
            "session_id": st.session_state.get("session_id"),
            "session_number": st.session_state.get("session_count", 0),
            "mode": mode,
            "started_at": recording_start.isoformat() if recording_start else None,
            "ended_at": now.isoformat(),
            "duration_seconds": duration,
        },
        # Planung der Lernenden (vor der √úbung)
        "learner_planning": {
            "goal": learner_goal,
            "context": learner_context,
            "submitted_at": recording_start.isoformat() if recording_start else None,
        },
        "transcript": transcript_text,
        "analysis": {
            "layer1_deterministic": kleiner_baer_result.get("metrics_summary", {}),
            "layer2_azure": None,
            "cefr": kleiner_baer_result.get("cefr", {}),
            "home_kpis": kleiner_baer_result.get("disce_metrics", {}),
            "hotspots": kleiner_baer_result.get("hotspots", []),
        },
        # Reflexion der Lernenden (nach der √úbung)
        "reflection": {
            "text": reflection,
            "submitted_at": now.isoformat() if reflection else None,
        },
    }


def update_coach_input_with_reflection(reflection_text: str):
    """Aktualisiert den coach_input mit der Reflexion."""
    if st.session_state.coach_input:
        st.session_state.coach_input["reflection"] = {
            "text": reflection_text,
            "submitted_at": datetime.now().isoformat(),
        }


def send_session_to_airtable() -> tuple[bool, str]:
    """
    Sendet die Session-Daten an Make Webhook ‚Üí Airtable.
    Make verteilt die Daten auf pretest_responses und Sessions.
    """
    try:
        coach_input = st.session_state.get("coach_input", {})
        kleiner_baer_result = st.session_state.get("kleiner_baer_result", {})
        task = get_task(st.session_state.selected_task_id) if st.session_state.selected_task_id else {}
        
        # CEFR-Daten aus Analyse
        cefr_data = kleiner_baer_result.get("cefr", {})
        
        # Session-Metadaten
        session_meta = coach_input.get("session_metadata", {})
        task_meta = coach_input.get("task_metadata", {})
        learner_planning = coach_input.get("learner_planning", {})
        reflection = coach_input.get("reflection", {})
        
        # Pretest-Daten holen
        pretest_data = get_pretest_data_for_airtable()
        
        # =====================================================================
        # FLACHER PAYLOAD (alle Felder auf oberster Ebene)
        # =====================================================================
        payload = {
            # --- Identifikation ---
            "session_id": st.session_state.get("session_id", ""),
            "user_code": st.session_state.get("user_code", "ANON"),
            "session_number": st.session_state.get("session_count", 0),
            "created_at": datetime.now().isoformat(),
            
            # --- Session-Daten ---
            "mode": session_meta.get("mode", "unknown"),
            "task_id": task_meta.get("task_id", ""),
            "task_situation": task_meta.get("situation", ""),
            "target_register": task_meta.get("target_register", ""),
            "target_level": task_meta.get("target_level", ""),
            "time_limit_seconds": task_meta.get("time_limit_seconds", 0),
            "duration_seconds": session_meta.get("duration_seconds", 0),
            "learner_goal": learner_planning.get("goal", ""),
            "learner_context": learner_planning.get("context", ""),
            "transcript": coach_input.get("transcript", ""),
            "reflection": reflection.get("text", ""),
            "cefr_label": cefr_data.get("label", ""),
            "cefr_score": cefr_data.get("score", 0.0),
            "metrics_json": json.dumps(kleiner_baer_result.get("disce_metrics", {})),
            
            # --- Pretest-Daten (NEU) ---
            "pretest_completed": pretest_data.get("pretest_completed", False),
            "pretest_completed_at": pretest_data.get("pretest_completed_at", ""),
            "cefr_self_overall": pretest_data.get("cefr_self_overall", ""),
            "cefr_self_speaking": pretest_data.get("cefr_self_speaking", ""),
            "has_official_cert": pretest_data.get("has_official_cert", False),
            "official_cert_type": pretest_data.get("official_cert_type", ""),
            "learning_duration_months": pretest_data.get("learning_duration_months", 0),
            "learning_context": pretest_data.get("learning_context", ""),
            "native_language": pretest_data.get("native_language", ""),
            "other_languages": pretest_data.get("other_languages", ""),
            "masq_total": pretest_data.get("masq_total", 0),
            "masq_level": pretest_data.get("masq_level", ""),
            "masq_pe_mean": pretest_data.get("masq_pe_mean", 0),
            "masq_ps_mean": pretest_data.get("masq_ps_mean", 0),
            "masq_pk_mean": pretest_data.get("masq_pk_mean", 0),
            "masq_mt_mean": pretest_data.get("masq_mt_mean", 0),
            "masq_da_mean": pretest_data.get("masq_da_mean", 0),
        }
        
        # An Make Webhook senden
        response = requests.post(
            MAKE_WEBHOOK_URL,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=10,
        )
        
        if response.status_code == 200:
            return True, "Session erfolgreich gespeichert!"
        else:
            return False, f"Fehler beim Speichern: HTTP {response.status_code}"
            
    except requests.exceptions.Timeout:
        return False, "Timeout: Server antwortet nicht."
    except requests.exceptions.RequestException as e:
        return False, f"Verbindungsfehler: {str(e)}"
    except Exception as e:
        return False, f"Fehler: {str(e)}"

# =============================================================================
# GPT FEEDBACK WRAPPER CLASS
# =============================================================================

class GPTFeedback:
    """Wrapper-Klasse f√ºr GPT-generiertes Feedback."""
    def __init__(self, text: str, cefr_data: dict):
        self.text = text
        self.cefr_label = cefr_data.get("label", "")
        self.cefr_score = cefr_data.get("score", 0)
        self.is_mock = False


# =============================================================================
# HEADER
# =============================================================================

st.title("üêª Gro√üer B√§r ‚Äì Speaking Coach")
st.markdown(
    "√úbe gesprochenes Deutsch mit strukturiertem Feedback. "
    "W√§hle eine Aufgabe, nimm dich auf, und erhalte Analyse + Coaching."
)

# =============================================================================
# SIDEBAR
# =============================================================================

with st.sidebar:
    # -------------------------------------------------------------------------
    # MINI-LOGIN: Nutzercode
    # -------------------------------------------------------------------------
    st.header("üë§ Dein Nutzercode")

    if st.session_state.user_code_confirmed:
        # Eingeloggt: Code anzeigen
        st.success(f"‚úÖ Eingeloggt als: **{st.session_state.user_code}**")
        st.caption("Dein Code verkn√ºpft alle deine Sessions.")
        
        # Pretest-Status anzeigen
        if st.session_state.get("pretest_completed", False):
            cefr_self = get_pretest_response("cefr_speaking", "‚Äì")
            st.info(f"üìä Selbsteinsch√§tzung: **{cefr_self}**")
            st.caption(f"Sessions: {st.session_state.get('session_count', 0)}")

        if st.button("üö™ Ausloggen", use_container_width=True):
            logout_user()
            st.rerun()

    else:
        # Nicht eingeloggt: Login-Formular
        st.markdown(
            "Gib deinen pers√∂nlichen Code ein, um deine Sessions zu verkn√ºpfen. "
            "Du kannst einen eigenen Code w√§hlen oder einen generieren lassen."
        )

        # Code-Eingabe
        user_code_input = st.text_input(
            "Dein Code:",
            value=st.session_state.user_code,
            max_chars=20,
            placeholder="z.B. ANNA2024 oder XYZ123",
            key="user_code_input",
        )

        col_login1, col_login2 = st.columns(2)

        with col_login1:
            if st.button("‚úÖ Best√§tigen", use_container_width=True):
                is_valid, message = validate_user_code(user_code_input)
                if is_valid:
                    st.session_state.user_code = user_code_input.upper()
                    st.session_state.user_code_confirmed = True
                    st.rerun()
                else:
                    st.error(message)

        with col_login2:
            if st.button("üé≤ Generieren", use_container_width=True):
                new_code = generate_user_code()
                st.session_state.user_code = new_code
                st.session_state.user_code_confirmed = True
                st.rerun()

        st.caption("üí° Merke dir deinen Code, um sp√§ter weiterzumachen!")

    st.markdown("---")

    # -------------------------------------------------------------------------
    # EINSTELLUNGEN
    # -------------------------------------------------------------------------
    st.header("‚öôÔ∏è Einstellungen")

    MOCK_MODE = st.checkbox(
        "Mock-Modus (ohne APIs)",
        value=True,
        help="Aktiviert Beispiel-Transkripte und Mock-Feedback f√ºr Testing",
    )

    # API-Status anzeigen
    if not MOCK_MODE:
        if OPENAI_AVAILABLE:
            st.success("‚úÖ OpenAI API verf√ºgbar")
        else:
            st.error("‚ùå OpenAI API nicht verf√ºgbar")
            st.caption("Aktiviere Mock-Modus oder pr√ºfe openai_services.py")

    st.markdown("---")

    if st.button("üîÑ Neue Session", use_container_width=True):
        reset_session()
        st.rerun()

    st.markdown("---")
    st.caption("Gro√üer B√§r v0.4 ‚Äì mit Pretest & OpenAI Integration")


# =============================================================================
# CHECK: Nutzercode erforderlich
# =============================================================================

# Aktuell: Code ist optional, aber empfohlen
if not st.session_state.user_code_confirmed:
    st.info(
        "üí° **Tipp:** Gib in der Sidebar deinen Nutzercode ein, "
        "um deine Sessions zu verkn√ºpfen und deinen Fortschritt zu tracken."
    )


# =============================================================================
# PRETEST FLOW (vor dem Hauptinhalt)
# =============================================================================

# Pretest nur anzeigen, wenn Nutzer eingeloggt ist
if st.session_state.user_code_confirmed:
    
    # Pr√ºfe ob Pretest n√∂tig
    if should_show_pretest(PRETEST_CONFIG):
        pretest_done = render_pretest(PRETEST_CONFIG)
        if not pretest_done:
            st.stop()  # Blockiere Hauptinhalt bis Pretest fertig
    
    # Pr√ºfe Level-Recheck (alle N Sessions)
    if st.session_state.get("pretest_show_recheck", False):
        render_level_recheck(PRETEST_CONFIG)
        st.markdown("---")


# =============================================================================
# PHASE 1: AUFGABE W√ÑHLEN + ZIEL SETZEN
# =============================================================================

if st.session_state.phase == "select":
    st.header("1Ô∏è‚É£ W√§hle deine Sprechaufgabe")

    # Task-Auswahl: get_task_choices() gibt Liste von (label, id) Tuples
    task_choices_list = get_task_choices()

    # Baue ein Dict: {label: id}
    task_choices = {label: tid for label, tid in task_choices_list}

    selected_label = st.selectbox(
        "Welche Situation m√∂chtest du √ºben?",
        options=list(task_choices.keys()),
        index=0,
    )

    task_id = task_choices[selected_label]
    task = get_task(task_id)

    # Task-Details anzeigen
    with st.expander("üìã Aufgabendetails", expanded=True):
        st.markdown(f"**Szenario:** {task['situation']}")
        st.markdown(f"**Zielregister:** {task['register']}")
        st.markdown(f"**Zeitrahmen:** {task['time_seconds']} Sekunden")
        st.markdown("---")
        st.markdown("**Deine Aufgabe:**")
        st.info(task["task"])

        if task.get("example_phrases"):
            st.markdown("**Beispielphrasen:**")
            for phrase in task["example_phrases"]:
                st.markdown(f"- _{phrase}_")

    # =========================================================================
    # PLANUNGSFELD: Pers√∂nliches Lernziel
    # =========================================================================
    st.markdown("---")
    st.subheader("üéØ Dein Lernziel f√ºr diese Session")

    st.markdown(
        "Bevor du startest: Was m√∂chtest du heute konkret √ºben oder verbessern? "
        "Das hilft dir, fokussiert zu bleiben ‚Äì und dem Coach, dir gezieltes Feedback zu geben."
    )

    # Leitfragen als Inspiration
    with st.expander("üí° Beispiele f√ºr Lernziele", expanded=False):
        st.markdown(
            """
- *Ich m√∂chte fl√ºssiger sprechen, ohne lange Pausen.*
- *Ich will formeller klingen ‚Äì weniger umgangssprachlich.*
- *Ich √ºbe, meine Argumente klar zu strukturieren.*
- *Ich m√∂chte Konjunktiv II sicher verwenden.*
- *Ich will meine Nervosit√§t in den Griff bekommen.*
- *Ich √ºbe, h√∂flich aber bestimmt zu formulieren.*
            """
        )

    learner_goal_input = st.text_area(
        "Was ist dein Ziel f√ºr diese √úbung?",
        value=st.session_state.learner_goal,
        height=80,
        placeholder="z.B. Ich m√∂chte heute √ºben, meine Punkte klar und strukturiert zu pr√§sentieren.",
        key="learner_goal_input",
    )

    # Optionales Kontextfeld
    with st.expander("üìù Optionaler Kontext (f√ºr wen / warum)", expanded=False):
        st.markdown(
            "Falls du einen konkreten Anlass hast, kannst du ihn hier beschreiben. "
            "Das macht das Feedback noch passender."
        )
        learner_context_input = st.text_area(
            "Kontext (optional):",
            value=st.session_state.learner_context,
            height=60,
            placeholder="z.B. Ich habe n√§chste Woche ein echtes Meeting mit meinem Chef.",
            key="learner_context_input",
        )

    # Meta-Prompt aus Task anzeigen (falls vorhanden)
    if task.get("meta_prompts", {}).get("plan"):
        st.info(f"üí° **Planungshinweis:** {task['meta_prompts']['plan']}")

    # Weiter-Button
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        # Button-Text anpassen je nachdem ob Ziel eingegeben
        if not learner_goal_input.strip():
            st.caption("üí° Tipp: Ein konkretes Lernziel hilft dir, fokussiert zu bleiben.")

        if st.button("üéôÔ∏è Aufnahme starten", type="primary", use_container_width=True):
            # Ziel und Kontext speichern
            st.session_state.learner_goal = learner_goal_input.strip()
            st.session_state.learner_context = (
                st.session_state.get("learner_context_input", "").strip()
            )
            st.session_state.selected_task_id = task_id
            st.session_state.phase = "record"
            st.session_state.recording_start = datetime.now()
            st.rerun()


# =============================================================================
# PHASE 2: AUFNAHME
# =============================================================================

elif st.session_state.phase == "record":
    st.header("2Ô∏è‚É£ Sprich jetzt!")

    task = get_task(st.session_state.selected_task_id)

    # Aufgabe anzeigen
    st.info(f"**Aufgabe:** {task['task']}")
    st.caption(
        f"‚è±Ô∏è Ziel: {task['time_seconds']} Sekunden | Register: {task['register']}"
    )

    # Lernziel anzeigen (zur Erinnerung)
    if st.session_state.learner_goal:
        st.success(f"üéØ **Dein Fokus:** {st.session_state.learner_goal}")

    # Meta-Prompt (Planungshinweis)
    if task.get("meta_prompts", {}).get("plan"):
        st.markdown(f"üí° *{task['meta_prompts']['plan']}*")

    st.markdown("---")

    # Audio-Aufnahme oder Mock-Modus
    if not MOCK_MODE:
        # Echter Modus: Audio-Aufnahme
        try:
            from audio_recorder_streamlit import audio_recorder

            st.markdown("### üéôÔ∏è Klicke zum Aufnehmen:")

            audio_bytes = audio_recorder(
                text="üéôÔ∏è Klicken zum Aufnehmen",
                recording_color="#e74c3c",
                neutral_color="#3498db",
                icon_size="2x",
                pause_threshold=3.0,
                sample_rate=16000,
                key="speaking_recorder",
            )

            if audio_bytes:
                st.session_state.audio_bytes = audio_bytes
                st.success("‚úÖ Aufnahme erhalten!")
                st.audio(audio_bytes, format="audio/wav")

                col1, col2 = st.columns(2)
                with col1:
                    if st.button("üîÑ Nochmal aufnehmen"):
                        st.session_state.audio_bytes = None
                        st.rerun()
                with col2:
                    if st.button("üì§ Zur Analyse senden", type="primary"):
                        st.session_state.phase = "feedback"
                        st.rerun()
            else:
                st.warning("üëÜ Klicke auf das Mikrofon um die Aufnahme zu starten.")

        except ImportError:
            st.error(
                "‚ùå Audio-Recorder nicht verf√ºgbar. "
                "Aktiviere den Mock-Modus in der Sidebar."
            )

    else:
        # Mock-Modus: Text-Eingabe statt Audio
        st.warning("üß™ **Mock-Modus aktiv** ‚Äì Gib deinen Text ein statt zu sprechen:")

        mock_text = st.text_area(
            "Dein Sprechtext (simuliert):",
            height=150,
            placeholder=(
                "Guten Tag, ich m√∂chte kurz den aktuellen Projektstand "
                "zusammenfassen..."
            ),
        )

        if mock_text:
            st.session_state.transcript = mock_text
            if st.button("üì§ Mit diesem Text Feedback erhalten", type="primary"):
                st.session_state.phase = "feedback"
                st.rerun()

    # Abbrechen-Option
    st.markdown("---")
    if st.button("‚Üê Andere Aufgabe w√§hlen"):
        st.session_state.phase = "select"
        st.session_state.audio_bytes = None
        st.session_state.transcript = None
        st.rerun()


# =============================================================================
# PHASE 3: FEEDBACK + REFLEXION
# =============================================================================

elif st.session_state.phase == "feedback":
    st.header("3Ô∏è‚É£ Dein Feedback")

    task = get_task(st.session_state.selected_task_id)

    # Berechne Aufnahmedauer
    if st.session_state.recording_start:
        duration = (
            datetime.now() - st.session_state.recording_start
        ).total_seconds()
    else:
        duration = 60.0

    # Feedback generieren (wenn noch nicht vorhanden)
    if st.session_state.feedback_result is None:
        with st.spinner("üîç Analysiere deine Aufnahme..."):

            if MOCK_MODE:
                # =============================================================
                # MOCK-MODUS (wie bisher)
                # =============================================================
                transcript_text = (
                    st.session_state.transcript
                    or "Dies ist ein Mock-Transkript f√ºr Testing."
                )

                # 1) Kleiner B√§r: deterministische Analyse (Schicht 1 + CEFR + KPIs)
                kb_result = analyze_text_for_llm(
                    transcript_text,
                    context={
                        "source": "grosser_baer",
                        "mode": "mock_speaking",
                        "task_id": st.session_state.selected_task_id,
                        "target_level": task.get("level"),
                        "target_register": task.get("register"),
                        "time_limit_seconds": task.get("time_seconds"),
                        "learner_goal": st.session_state.learner_goal,
                        "learner_context": st.session_state.learner_context,
                        "user_code": st.session_state.user_code,
                        # NEU: MASQ-Scores aus Pretest
                        "masq_scores": st.session_state.get("pretest_responses", {}).get("masq_scores", {}),
                    },
                )
                st.session_state.kleiner_baer_result = kb_result

                # 2) Coach-Input-Block bauen
                coach_input = build_coach_input(
                    transcript_text=transcript_text,
                    task=task,
                    duration=duration,
                    mode="mock_speaking",
                    kleiner_baer_result=kb_result,
                    learner_goal=st.session_state.learner_goal,
                    learner_context=st.session_state.learner_context,
                    reflection="",
                )
                st.session_state.coach_input = coach_input

                # 3) Mock-Feedback (altes System)
                feedback = generate_feedback(
                    transcript=transcript_text,
                    task=task,
                    prosody=None,
                    use_mock=True,
                )

                st.session_state.feedback_result = feedback
                st.session_state.transcript_text = transcript_text

            else:
                # =============================================================
                # ECHTER MODUS MIT OPENAI
                # =============================================================
                
                # 1) Audio transkribieren mit Whisper (wenn Audio vorhanden)
                if st.session_state.audio_bytes and OPENAI_AVAILABLE:
                    with st.spinner("üéôÔ∏è Transkribiere Audio mit Whisper..."):
                        try:
                            transcript_text = transcribe_audio(st.session_state.audio_bytes)
                        except Exception as e:
                            st.error(f"‚ùå Whisper-Fehler: {str(e)}")
                            transcript_text = st.session_state.transcript or "Transkription fehlgeschlagen."
                else:
                    # Fallback: Text aus Mock-Eingabe oder Platzhalter
                    transcript_text = st.session_state.transcript or "Kein Text vorhanden."
                
                st.session_state.transcript_text = transcript_text

                # 2) Kleiner B√§r: deterministische Analyse
                kb_result = analyze_text_for_llm(
                    transcript_text,
                    context={
                        "source": "grosser_baer",
                        "mode": "speaking",
                        "task_id": st.session_state.selected_task_id,
                        "target_level": task.get("level"),
                        "target_register": task.get("register"),
                        "time_limit_seconds": task.get("time_seconds"),
                        "learner_goal": st.session_state.learner_goal,
                        "learner_context": st.session_state.learner_context,
                        "user_code": st.session_state.user_code,
                        # NEU: MASQ-Scores aus Pretest
                        "masq_scores": st.session_state.get("pretest_responses", {}).get("masq_scores", {}),
                    },
                )
                st.session_state.kleiner_baer_result = kb_result

                # 3) Coach-Input-Block bauen
                coach_input = build_coach_input(
                    transcript_text=transcript_text,
                    task=task,
                    duration=duration,
                    mode="speaking",
                    kleiner_baer_result=kb_result,
                    learner_goal=st.session_state.learner_goal,
                    learner_context=st.session_state.learner_context,
                    reflection="",
                )
                st.session_state.coach_input = coach_input

                # 4) GPT-4o-mini Coaching-Feedback
                if OPENAI_AVAILABLE:
                    with st.spinner("ü§ñ Generiere Coaching-Feedback mit GPT..."):
                        try:
                            gpt_feedback_text = generate_coach_feedback(coach_input)
                            feedback = GPTFeedback(gpt_feedback_text, kb_result.get("cefr", {}))
                        except Exception as e:
                            st.error(f"‚ùå GPT-Fehler: {str(e)}")
                            # Fallback auf Mock-Feedback
                            feedback = generate_feedback(
                                transcript=transcript_text,
                                task=task,
                                prosody=None,
                                use_mock=True,
                            )
                else:
                    # OpenAI nicht verf√ºgbar ‚Üí Mock-Feedback
                    st.warning("‚ö†Ô∏è OpenAI nicht verf√ºgbar, nutze Mock-Feedback")
                    feedback = generate_feedback(
                        transcript=transcript_text,
                        task=task,
                        prosody=None,
                        use_mock=True,
                    )

                st.session_state.feedback_result = feedback

    # Ergebnisse aus Session holen
    feedback = st.session_state.feedback_result
    transcript_text = st.session_state.get("transcript_text", "")

    kleiner_baer_result = st.session_state.get("kleiner_baer_result")
    coach_input = st.session_state.get("coach_input")
    cefr_from_kb = None
    if kleiner_baer_result and "cefr" in kleiner_baer_result:
        cefr_from_kb = kleiner_baer_result["cefr"]

    # Lernziel zur Erinnerung anzeigen
    if st.session_state.learner_goal:
        st.info(f"üéØ **Dein Fokus war:** {st.session_state.learner_goal}")

    # Tabs f√ºr verschiedene Ansichten
    tab_feedback, tab_transcript, tab_metrics, tab_api = st.tabs(
        ["üí¨ Feedback", "üìù Transkript", "üìä Metriken", "üîå LLM-Input"]
    )

    # -------------------------------------------------------------------------
    # Tab: Feedback
    # -------------------------------------------------------------------------
    with tab_feedback:
        # CEFR-Badge (wenn m√∂glich aus Kleiner B√§r)
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if cefr_from_kb:
                # Zeige auch Selbsteinsch√§tzung zum Vergleich
                cefr_self = get_pretest_response("cefr_speaking")
                delta_text = f"Score: {cefr_from_kb.get('score', 0.0):.2f}"
                if cefr_self:
                    delta_text += f" | Selbst: {cefr_self}"
                
                st.metric(
                    "Gesch√§tztes Niveau",
                    cefr_from_kb.get("label", "‚Äì"),
                    delta=delta_text,
                )
            elif hasattr(feedback, "cefr_label") and feedback.cefr_label:
                st.metric(
                    "Gesch√§tztes Niveau",
                    feedback.cefr_label,
                    delta=(
                        f"Score: {feedback.cefr_score:.1f}"
                        if hasattr(feedback, "cefr_score") and feedback.cefr_score
                        else None
                    ),
                )

        st.markdown("---")

        # Feedback anzeigen - unterscheide zwischen GPT und Mock
        if hasattr(feedback, 'text'):
            # GPT-Feedback (neues Format)
            st.markdown(feedback.text)
        else:
            # Altes Mock-Format
            st.markdown(format_feedback_markdown(feedback))

        # Hinweis zum Modus
        if hasattr(feedback, "is_mock") and feedback.is_mock:
            st.caption("‚ÑπÔ∏è Mock-Modus: Dies ist simuliertes Feedback f√ºr Testing.")
        elif not MOCK_MODE and OPENAI_AVAILABLE:
            st.caption("ü§ñ Feedback generiert mit GPT-4o-mini")

    # -------------------------------------------------------------------------
    # Tab: Transkript
    # -------------------------------------------------------------------------
    with tab_transcript:
        st.subheader("Dein Text")
        st.markdown(f"> {transcript_text}")

        st.markdown("---")

        col1, col2 = st.columns(2)
        with col1:
            word_count = len(transcript_text.split()) if transcript_text else 0
            st.metric("W√∂rter", word_count)
        with col2:
            st.metric("Dauer", f"{duration:.0f}s")

        if MOCK_MODE:
            st.caption("‚ÑπÔ∏è Mock-Modus: Eingegebener Text")
        elif not MOCK_MODE and OPENAI_AVAILABLE:
            st.caption("üéôÔ∏è Transkribiert mit Whisper")

    # -------------------------------------------------------------------------
    # Tab: Metriken
    # -------------------------------------------------------------------------
    with tab_metrics:
        st.subheader("Prosodie & Sprechtempo")

        col1, col2, col3 = st.columns(3)

        with col1:
            word_count = len(transcript_text.split()) if transcript_text else 0
            wpm = (word_count / duration * 60) if duration > 0 else 0
            st.metric(
                "Sprechtempo",
                f"{wpm:.0f} WPM",
                help="W√∂rter pro Minute (120-150 ist normal)",
            )

        with col2:
            # Mock: Z√§hle typische F√ºllw√∂rter
            filler_words = ["√§hm", "also", "quasi", "sozusagen", "halt", "eigentlich"]
            filler_count = sum(transcript_text.lower().count(fw) for fw in filler_words)
            st.metric("F√ºllw√∂rter", filler_count, help="√§hm, also, quasi, etc.")

        with col3:
            st.metric("Fl√ºssigkeit", "‚Äì" if MOCK_MODE else "75%")

        st.markdown("---")

        # Disce-Metriken
        st.subheader("Disce-Dimensionen")

        disce = None
        if kleiner_baer_result:
            # Echte KPIs aus Kleiner B√§r / build_disce_metrics
            disce = kleiner_baer_result.get("disce_metrics")
        elif hasattr(feedback, "disce_metrics") and feedback.disce_metrics:
            # Fallback, falls Feedback sie intern schon mitbringt
            disce = feedback.disce_metrics

        if disce:
            cols = st.columns(5)
            metrics = [
                ("Register", "level_match"),
                ("Prosodie", "prosody_intelligibility"),
                ("Koh√§sion", "sentence_cohesion"),
                ("Task-Fit", "task_exam_fit"),
                ("Fortschritt", "goal_progress"),
            ]
            for col, (label, key) in zip(cols, metrics):
                val = float(disce.get(key, 0))
                col.metric(label, f"{val:.0%}")
        else:
            st.info("Noch keine Disce-Metriken verf√ºgbar.")

        # NEU: MASQ-Profil anzeigen (wenn Pretest abgeschlossen)
        st.markdown("---")
        st.subheader("Metakognitives Profil (MASQ)")
        
        masq_scores = st.session_state.get("pretest_responses", {}).get("masq_scores", {})
        if masq_scores and masq_scores.get("factors"):
            factors = masq_scores.get("factors", {})
            cols = st.columns(5)
            factor_labels = {
                "PE": ("Planung", "Planning & Evaluation"),
                "PS": ("Probleml√∂sung", "Problem-Solving"),
                "PK": ("Selbstbild", "Person Knowledge"),
                "DA": ("Fokus", "Directed Attention"),
                "MT": ("√úbersetzung", "Mental Translation"),
            }
            for col, (key, (short, full)) in zip(cols, factor_labels.items()):
                if key in factors:
                    mean = factors[key].get("mean", 0)
                    # MT ist negativ (niedrig = gut)
                    if key == "MT":
                        col.metric(short, f"{mean:.1f}/5", delta="‚Üì besser", delta_color="inverse", help=full)
                    else:
                        col.metric(short, f"{mean:.1f}/5", help=full)
            
            st.caption(f"Gesamtscore: {masq_scores.get('total', 0)} ‚Äì {masq_scores.get('level_label', '')}")
        else:
            st.info("MASQ-Profil wird nach dem Pretest angezeigt.")

        if MOCK_MODE:
            st.caption(
                "‚ÑπÔ∏è Mock-Modus: Audio-Prosodie ist noch simuliert ‚Äì "
                "Textmetriken sind bereits echt."
            )

    # -------------------------------------------------------------------------
    # Tab: LLM-Input
    # -------------------------------------------------------------------------
    with tab_api:
        st.subheader("LLM-Coach Input (JSON)")
        st.write(
            "Dieser Block wird an die LLM-Coach-API gesendet. "
            "Er enth√§lt Task-Metadaten, Transkript, Pretest-Daten und deterministische Analyse "
            "nach dem Disce-Diagnostikmodell."
        )

        if coach_input:
            st.json(coach_input)
        else:
            st.info(
                "Noch kein Coach-Input verf√ºgbar. "
                "Bitte zuerst eine Aufgabe abschlie√üen."
            )

    # =========================================================================
    # REFLEXIONSFELD (nach den Tabs)
    # =========================================================================
    st.markdown("---")
    st.header("4Ô∏è‚É£ Deine Reflexion")

    st.markdown(
        "Nimm dir einen Moment, um √ºber deine √úbung nachzudenken. "
        "Das hilft dir, das Gelernte zu verankern."
    )

    # Leitfragen als Inspiration ‚Äì angepasst ans Lernziel + MASQ-basiert
    with st.expander("üí° Leitfragen zur Reflexion", expanded=False):
        reflection_prompts = """
**Was ist mir gut gelungen?**
- Wortwahl, Struktur, Fl√ºssigkeit

**Was war schwierig?**
- Ein bestimmtes Wort, die Satzstellung, das Tempo

**Strategien (Problem-Solving):**
- Hast du W√∂rter umschrieben, wenn dir etwas nicht eingefallen ist?
- Hast du dich selbst korrigiert?

**Mentale √úbersetzung:**
- Hast du w√§hrend des Sprechens im Kopf √ºbersetzt?
- Konntest du direkt auf Deutsch denken?

**Fokus & Konzentration:**
- Konntest du dich auf die Aufgabe konzentrieren?
- Warst du abgelenkt?

**Was will ich beim n√§chsten Mal anders machen?**
"""
        # Falls Lernziel vorhanden, zus√§tzliche Frage
        if st.session_state.learner_goal:
            reflection_prompts += (
                f"\n**Bezogen auf dein Ziel** "
                f"({st.session_state.learner_goal}): Wie gut hast du es erreicht?"
            )

        st.markdown(reflection_prompts)

    # Reflexions-Textfeld
    reflection_input = st.text_area(
        "Deine Gedanken:",
        value=st.session_state.reflection_text,
        height=120,
        placeholder="Was nimmst du aus dieser √úbung mit? Was machst du n√§chstes Mal anders?",
        key="reflection_input",
    )

    # Speichern-Button f√ºr Reflexion
    col_ref1, col_ref2 = st.columns([3, 1])
    with col_ref2:
        if st.button("‚úÖ Reflexion speichern", type="primary", use_container_width=True):
            st.session_state.reflection_text = reflection_input
            update_coach_input_with_reflection(reflection_input)
            st.session_state.reflection_saved = True
            st.rerun()

    # Best√§tigung anzeigen
    if st.session_state.reflection_saved and st.session_state.reflection_text:
        st.success("‚úÖ Reflexion gespeichert!")
        st.markdown(f"**Deine Reflexion:** _{st.session_state.reflection_text}_")

    # =========================================================================
    # AKTIONEN
    # =========================================================================
    st.markdown("---")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("üîÑ Nochmal versuchen"):
            st.session_state.phase = "record"
            st.session_state.audio_bytes = None
            st.session_state.transcript = None
            st.session_state.feedback_result = None
            st.session_state.kleiner_baer_result = None
            st.session_state.coach_input = None
            st.session_state.reflection_text = ""
            st.session_state.reflection_saved = False
            st.session_state.session_saved = False
            st.rerun()

    with col2:
        if st.button("üìã Andere Aufgabe"):
            reset_session()
            st.rerun()

    with col3:
        # Session speichern Button mit Webhook-Anbindung
        if st.session_state.session_saved:
            st.success("‚úÖ Gespeichert!")
        else:
            if st.button("üíæ Session speichern", type="primary"):
                # Reflexion aktualisieren falls vorhanden
                if reflection_input:
                    st.session_state.reflection_text = reflection_input
                    update_coach_input_with_reflection(reflection_input)
                
                # An Airtable senden
                with st.spinner("Speichere Session..."):
                    success, message = send_session_to_airtable()
                
                if success:
                    st.session_state.session_saved = True
                    st.rerun()
                else:
                    st.error(f"‚ùå {message}")


# =============================================================================
# FOOTER
# =============================================================================

st.markdown("---")
st.caption(
    "üêª Gro√üer B√§r v0.4 ‚Äì Pretest + Kleiner B√§r Textanalyse + OpenAI (Whisper & GPT-4o-mini)"
)
